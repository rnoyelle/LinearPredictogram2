{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.cnn.matnpyio as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "### base path ###\n",
    "#################\n",
    "\n",
    "# path to raw_path :  base_path/sess_no/session01/file.mat\n",
    "base_path = '/media/rudy/disk2/lucy/' \n",
    "\n",
    "# path where the csv files are\n",
    "result_path = '/home/rudy/Python2/regression_linear2/result_ridge/'\n",
    "\n",
    "# path where to save numpy files\n",
    "summary_path = '/home/rudy/Python2/regression_linear2/results/summary/'\n",
    "\n",
    "# path where to save figure\n",
    "figure_path = '/home/rudy/Python2/regresion_linear2/results/figure/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of session \n",
    "csv_files = os.listdir(result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['result_sess_no_141015channel_to_channel_all_interval_ridge.csv',\n",
       " 'result_sess_no_141014channel_to_channel_all_interval_ridge.csv',\n",
       " 'result_sess_no_141016channel_to_channel_all_interval_ridge.csv']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "session =  [ re.findall('\\d+', el)[0] for el in csv_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['141015', '141014', '141016']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "lowcut, highcut , order = 7, 12, 3\n",
    "str_freq = 'low'+str(lowcut)+'high'+str(highcut)+'order'+str(order)        \n",
    "\n",
    "window_size = 200\n",
    "only_correct_trials = True\n",
    "\n",
    "Cortex = ['Visual', 'Prefrontal', 'Motor', 'Parietal', 'Somatosensory'] # order matters\n",
    "\n",
    "# les time-course vont Ãªtre sorties dans cet ordre :\n",
    "intervals = ['align_on_sample_from_time_-700_to_time_-500',\n",
    "       'align_on_sample_from_time_-600_to_time_-400',\n",
    "       'align_on_sample_from_time_-500_to_time_-300',\n",
    "       'align_on_sample_from_time_-400_to_time_-200',\n",
    "       'align_on_sample_from_time_-300_to_time_-100',\n",
    "       'align_on_sample_from_time_-200_to_time_0',\n",
    "       'align_on_sample_from_time_-100_to_time_100',\n",
    "       'align_on_sample_from_time_0_to_time_200',\n",
    "       'align_on_sample_from_time_100_to_time_300',\n",
    "       'align_on_sample_from_time_200_to_time_400',\n",
    "       'align_on_sample_from_time_300_to_time_500',\n",
    "       'align_on_sample_from_time_400_to_time_600',\n",
    "       'align_on_sample_from_time_500_to_time_700',\n",
    "       'align_on_sample_from_time_600_to_time_800',\n",
    "       'align_on_sample_from_time_700_to_time_900',\n",
    "       'align_on_sample_from_time_800_to_time_1000',\n",
    "       'align_on_sample_from_time_900_to_time_1100',\n",
    "       'align_on_sample_from_time_1000_to_time_1200',\n",
    "       'align_on_sample_from_time_1100_to_time_1300',\n",
    "       'align_on_sample_from_time_1200_to_time_1400',\n",
    "       'align_on_sample_from_time_1300_to_time_1500'] # must be sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = []\n",
    "\n",
    "\n",
    "align_on, from_time, to_time = 'sample', -700, 500 + 1000 \n",
    "window_size = 200\n",
    "step = 100\n",
    "\n",
    "for n_step in range( int( ( to_time - from_time - window_size)/step) +1 ) :\n",
    "    intervals.append( 'align_on_' + align_on + '_from_time_' + str(from_time +  n_step * step) +'_to_time_'+ str(from_time +  n_step * step + window_size))\n",
    "    \n",
    "align_on, from_time, to_time = 'match', -500, 0 + 1900 \n",
    "window_size = 200\n",
    "step = 100\n",
    "\n",
    "for n_step in range( int( ( to_time - from_time - window_size)/step) +1 ) :\n",
    "    intervals.append( 'align_on_' + align_on + '_from_time_' + str(from_time +  n_step * step) +'_to_time_'+ str(from_time +  n_step * step + window_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141015\n",
      "DP\n",
      "DP\n",
      "MT\n",
      "MT\n",
      "V1\n",
      "V1\n",
      "V1\n",
      "V1\n",
      "V1\n",
      "V1\n",
      "V1\n",
      "V1\n",
      "V1\n",
      "V1\n",
      "V1\n",
      "V2\n",
      "V2\n",
      "V2\n",
      "V2\n",
      "V2\n",
      "V4t\n",
      "V4t\n",
      "V6A\n",
      "V6A\n",
      "a8B\n",
      "a8B\n",
      "a8L\n",
      "a8L\n",
      "a8L\n",
      "a8M\n",
      "a8M\n",
      "a8M\n",
      "a8r\n",
      "a8r\n",
      "a9/46D\n",
      "F1\n",
      "F1\n",
      "F1\n",
      "F1\n",
      "F2\n",
      "F2\n",
      "F2\n",
      "F2\n",
      "F2\n",
      "F2\n",
      "F6\n",
      "F7\n",
      "F7\n",
      "F7\n",
      "AIP\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for sess_no in session :\n",
    "    print(sess_no)\n",
    "    \n",
    "    #################\n",
    "    # LOAD CSV FILE #\n",
    "    #################\n",
    "    \n",
    "    # recording info path\n",
    "    rinfo_path = base_path +sess_no+'/session01/' + 'recording_info.mat'\n",
    "    # file path\n",
    "    file_name = result_path+ 'result_sess_no_'+sess_no+'channel_to_channel_all_interval_ridge.csv'\n",
    "       \n",
    "    # load csv file \n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "    \n",
    "    df = df[ (df['alpha']==alpha) &  (df['str_freq']==str_freq ) & (df['window_size'] == window_size) \n",
    "            & (df['only_correct_trials']==only_correct_trials) ]\n",
    "\n",
    "    \n",
    "    \n",
    "    # get list of areas in the right order : sorted by cortex then sorted by area\n",
    "    target_areas = []\n",
    "    for cortex in Cortex : \n",
    "        areas = io.get_area_cortex(rinfo_path, cortex, unique = False)\n",
    "        for area in sorted(areas) :\n",
    "            target_areas.append(area)\n",
    "            \n",
    "    # get list of num for distinguish 2 electrodes/channels from the same area\n",
    "    dico = {}\n",
    "    for area in np.unique(target_areas):\n",
    "        dico[area] = 0\n",
    "\n",
    "    num_areas = []\n",
    "    for i, area in enumerate(target_areas) :\n",
    "        num_areas.append( dico[area] )\n",
    "        dico[area] +=1\n",
    "        \n",
    "        \n",
    "    # build matrix\n",
    "    FC = np.zeros( (len(target_areas), len(target_areas), len(intervals)) )\n",
    "    FC_error_bar = np.zeros( (len(target_areas), len(target_areas), len(intervals)) )\n",
    "    \n",
    "    \n",
    "    for i, area1 in enumerate(target_areas):\n",
    "        print(area1)\n",
    "        for j, area2 in enumerate(target_areas):\n",
    "            for t, interval in enumerate(intervals) :\n",
    "                \n",
    "                r2_test = df[ (df['area1'] == area1) & (df['area2'] == area2) & \n",
    "                             (df['interval'] == interval) \n",
    "                             & (df['num1'] == num_areas[i]) & (df['num2'] == num_areas[j]) ]['r2_test'].values\n",
    "                \n",
    "                error_bar = df[ (df['area1'] == area1) & (df['area2'] == area2) & \n",
    "                             (df['interval'] == interval) \n",
    "                             & (df['num1'] == num_areas[i]) & (df['num2'] == num_areas[j]) ]['r2_test_error_bar'].values\n",
    "                \n",
    "                if len(r2_test) > 0 :\n",
    "                    \n",
    "                    FC[i,j,t] = r2_test[0] # take the first value \n",
    "                    #FC[i,j,t] = np.mean(r2_test) # take the mean of values\n",
    "                    \n",
    "                    FC_error_bar[i,j,t] = error_bar[0] # take the first value\n",
    "                    #FC_error_bar[i,j,t] = np.sqrt( np.sum(error_bar**2) )/len(error_bar) # take the mean of values\n",
    "                    \n",
    "                else:\n",
    "                    print('No value for:\\narea1',area1,'\\narea2',area2,'\\ninterval', interval)\n",
    "                    \n",
    "    # Create directory if not exists\n",
    "    directory = summary_path +sess_no+'/'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    ####################\n",
    "    # SAVE NUMPY FILES #\n",
    "    ####################\n",
    "    \n",
    "    \n",
    "    # time course\n",
    "    np.save(directory + 'FC_all_channels_low'+str(lowcut)+'high'+str(highcut)+'order'+str(order)+'_all_intervals.npy', FC)\n",
    "    # error bar\n",
    "    np.save(directory + 'FC_all_channels_low'+str(lowcut)+'high'+str(highcut)+'order'+str(order)+'_all_intervals_error_bar.npy', FC_error_bar)\n",
    "    # label/ area names\n",
    "    np.save(directory + 'label.npy', np.array(target_areas) )   \n",
    "    # save time\n",
    "    np.save(directory + 'time.npy', np.array(intervals))\n",
    "    \n",
    "#     ###########\n",
    "#     # plot it #\n",
    "#     ###########\n",
    "    \n",
    "#     for t, interval in enumerate(intervals):\n",
    "        \n",
    "#         fig, ax = plt.subplots(figsize=(15,15))\n",
    "#         im = ax.imshow(FC[:,:,t], vmin=0)#, vmax=1.0)# cmap='jet')\n",
    "#         fig.colorbar(im)\n",
    "        \n",
    "#         label2 = target_areas\n",
    "#         label1 = target_areas\n",
    "\n",
    "#         # We want to show all ticks...\n",
    "#         ax.set_xticks(np.arange(len(label2)))\n",
    "#         ax.set_yticks(np.arange(len(label1)))\n",
    "#         # ... and label them with the respective list entries\n",
    "#         ax.set_xticklabels(label2, linespacing=5)\n",
    "#         ax.set_yticklabels(label1, linespacing=5)\n",
    "\n",
    "#         # Rotate the tick labels and set their alignment.\n",
    "#         plt.setp(ax.get_xticklabels(), rotation=0, ha=\"right\",\n",
    "#                  rotation_mode=\"anchor\")\n",
    "\n",
    "#         # Loop over data dimensions and create text annotations.\n",
    "#         # for i in range(len(label1)):\n",
    "#         #     for j in range(len(label2)):\n",
    "#         #         if round(FC[i, j],3) < 0.8* FC.max() :\n",
    "#         #             text = ax.text(j, i, round(FC[i, j],1),\n",
    "#         #                            ha=\"center\", va=\"center\", color=\"w\")\n",
    "#         #         else:\n",
    "#         #             text = ax.text(j, i, round(FC[i, j],1),\n",
    "#         #                            ha=\"center\", va=\"center\", color=\"b\")\n",
    "\n",
    "\n",
    "#         ax.set_title(\"R_squared\"+interval)\n",
    "#         #fig.tight_layout()\n",
    "\n",
    "#         # save matrix and labels as numpy file (make directory if not exists)\n",
    "\n",
    "#         # create directory if not exists\n",
    "#         directory = figure_path +sess_no+'/'\n",
    "#         if not os.path.exists(directory):\n",
    "#             os.makedirs(directory)\n",
    "\n",
    "\n",
    "#         # save plot as jpg file\n",
    "#         plt.savefig(directory+str(t)+'.FC_all_channels_low'+str(lowcut)+'high'+str(highcut)+'order'+str(order)+'_'+interval+'jpg')\n",
    "#         plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['session', 'area1', 'num1', 'area2', 'num2', 'cortex1', 'cortex2',\n",
       "       'interval', 'str_freq', 'window_size', 'len(ind_test)',\n",
       "       'len(ind_train)', 'alpha', 'n_chans1', 'n_chans2',\n",
       "       'only_correct_trials', 'r2_train', 'r2_test', 'r2_train_error_bar',\n",
       "       'r2_test_error_bar', 'renorm', 'seed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
